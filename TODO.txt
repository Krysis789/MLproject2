Problems to solve:

- last word from vocab is missing in cooc -> investigate teachers code in cooc.py
- tweets containing no word in vocab get represented with NaN weights, that are not supported by classifier (not a problem to drop in train, but missing prediction if it occurs in test)

Optimization to try:
- Try different kind of classifier, different parameters, etc.
- Optimize their parameters

- Custom tweet representation
	- Negations (puting "not" with the following word to form one word for instance)
	- Plurals (separate words or not ??)
	- Vocab/Grammar mistakes + letter repetitions ("I loooooove chocolate" = "I love chocolate")
	- tokenizer specialised in social media language
	- Get rid of some particular words (list of stop words, for instance "a", "the",... ??)
	- Punctuation ???
	- Change the minimum number of occurance required to be kept in vocab
	- Remove duplicate tweets in train
	- Include test data for creation of vocab and cooc